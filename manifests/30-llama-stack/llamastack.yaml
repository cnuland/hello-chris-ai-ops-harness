# Llama Stack deployment reference
#
# NOTE: Llama Stack is already deployed on this cluster in the 'llama-stack' namespace.
# This manifest documents the existing deployment for reference and reproducibility.
# DO NOT apply this unless you need to recreate the Llama Stack deployment.
#
# Current vLLM deployment details:
#   - Service: granite-4-server.llm-serving.svc.cluster.local:8080
#   - Model: granite-4 (served via vLLM OpenAI-compatible API)
#   - API: /v1/chat/completions (OpenAI-compatible)
#
# Legacy Llama Stack deployment details (no longer used):
#   - Service: llama-stack-server.llama-stack.svc:8080
#   - Route: llama-stack-server-llama-stack.apps.ironman.cjlabs.dev
#   - Model backend: Ollama at ollama-gpt-oss-120b.gpt-oss.svc:11434
#   - Models: gpt-oss:120b, gpt-oss:20b
#   - APIs: agents, inference, safety, tool_runtime, vector_io, files
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama-stack-server
  namespace: llama-stack
  labels:
    app: llama-stack-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama-stack-server
  template:
    metadata:
      labels:
        app: llama-stack-server
    spec:
      containers:
        - name: server
          image: llamastack/distribution-starter:latest
          imagePullPolicy: Always
          command: ["llama"]
          args: ["stack", "run", "/app/run.yaml", "--port", "8080"]
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: HOME
              value: /app-data
            - name: LLAMA_STACK_PORT
              value: "8080"
            - name: SQLITE_STORE_DIR
              value: /app-data/sqlite
            - name: FILES_STORAGE_DIR
              value: /app-data/files
            - name: OLLAMA_URL
              value: "http://ollama-gpt-oss-120b.gpt-oss.svc:11434"
          resources:
            requests:
              cpu: 250m
              memory: 512Mi
            limits:
              cpu: "1"
              memory: 2Gi
          readinessProbe:
            httpGet:
              path: /docs
              port: http
            initialDelaySeconds: 20
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /docs
              port: http
            initialDelaySeconds: 60
            periodSeconds: 30
          volumeMounts:
            - name: llama-data
              mountPath: /app-data
            - name: config
              mountPath: /app/run.yaml
              subPath: stack.yaml
      volumes:
        - name: llama-data
          emptyDir: {}
        - name: config
          configMap:
            name: llama-stack-config
---
apiVersion: v1
kind: Service
metadata:
  name: llama-stack-server
  namespace: llama-stack
  labels:
    app: llama-stack-server
spec:
  ports:
    - port: 8080
      targetPort: 8080
      name: http
  selector:
    app: llama-stack-server
